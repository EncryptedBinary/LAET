{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a2a7c9-8a6f-466c-8ef3-abd6ab8de378",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install flash-attn torch accelerate transformers datasets scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c2b5785-07dd-4825-9784-b75cf7317b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from datasets import load_dataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae28cbb7-c558-42a1-b1d3-82e6fe031663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cc0c1099f444db78d64d606b63082da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model and tokenizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"Model_Name\", \n",
    "    device_map=\"cuda\", \n",
    "    torch_dtype=\"auto\", \n",
    "    trust_remote_code=True, \n",
    ").to(device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Model_Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c7aa44-a561-42b1-a728-d5de7d5e92b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = load_dataset('Dataset_Name')\n",
    "\n",
    "# Dataset features\n",
    "train_data = dataset['train']\n",
    "valid_data = dataset['valid']\n",
    "test_data = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03e39a47-ea01-4ad6-8bcb-f22008e3d697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storage for layer representations and classifiers\n",
    "tot_layer = len(model.model.layers)+1  # Total layers in the model\n",
    "layer_representations = [[] for _ in range(tot_layer)]\n",
    "classifiers = []\n",
    "layer_metrics = []  # Store metrics for each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb2ec316-922f-4825-9fad-886e846516b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a shared-head neural network classifier\n",
    "class SharedNN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(SharedNN, self).__init__()\n",
    "        self.shared_fc1 = nn.Linear(input_size, 128)\n",
    "        self.shared_relu = nn.ReLU()\n",
    "        self.shared_fc2 = nn.Linear(128, 64)\n",
    "        self.shared_relu2 = nn.ReLU()\n",
    "        self.output_layer = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.shared_fc1(x)\n",
    "        x = self.shared_relu(x)\n",
    "        x = self.shared_fc2(x)\n",
    "        x = self.shared_relu2(x)\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b2f64f-1f4b-4119-9447-e44d58d10e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "def preprocess(example):\n",
    "    query = example['query']\n",
    "    input_text = f\"{query}\"\n",
    "    label = example['gold']\n",
    "    return input_text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5addaab6-2f53-4a0f-9359-d26cdcf365d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect representations for each layer\n",
    "def collect_representations(data):\n",
    "    for example in tqdm(data):\n",
    "        input_text, label = preprocess(example)\n",
    "        with torch.no_grad():\n",
    "            inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=400).to(device)\n",
    "            outputs = model(**inputs, output_hidden_states=True)\n",
    "\n",
    "        hidden_states = outputs.hidden_states\n",
    "        for i, hs in enumerate(hidden_states):\n",
    "            hs_last = hs[0, -1, :].float().cpu().numpy()\n",
    "            layer_representations[i].append((hs_last, label))\n",
    "\n",
    "collect_representations(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ee1ebf-f856-4635-aa1a-85daf4583aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train classifiers for each layer\n",
    "shared_nn = SharedNN(input_size=model.config.hidden_size, num_classes=len(set(train_data['gold']))).to(device)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abf4bd9-2e09-483c-b182-a5ae28c406a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0: Accuracy=0.5806451612903226, F1=0.42659644502962474\n",
      "Layer 1: Accuracy=0.5806451612903226, F1=0.42659644502962474\n",
      "Layer 2: Accuracy=0.5806451612903226, F1=0.42659644502962474\n",
      "Layer 3: Accuracy=0.5806451612903226, F1=0.42659644502962474\n",
      "Layer 4: Accuracy=0.6, F1=0.4733455539617122\n",
      "Layer 5: Accuracy=0.6564516129032258, F1=0.5849051318735032\n",
      "Layer 6: Accuracy=0.6564516129032258, F1=0.5849051318735032\n",
      "Layer 7: Accuracy=0.6532258064516129, F1=0.5956133822636247\n",
      "Layer 8: Accuracy=0.6629032258064517, F1=0.6091863301156157\n",
      "Layer 9: Accuracy=0.6645161290322581, F1=0.6027132951462165\n",
      "Layer 10: Accuracy=0.6725806451612903, F1=0.618333481035094\n",
      "Layer 11: Accuracy=0.6709677419354839, F1=0.6250487988235577\n",
      "Layer 12: Accuracy=0.6612903225806451, F1=0.6011536329115249\n",
      "Layer 13: Accuracy=0.6709677419354839, F1=0.6142827528194994\n",
      "Layer 14: Accuracy=0.7645161290322581, F1=0.7526584669044527\n",
      "Layer 15: Accuracy=0.8064516129032258, F1=0.8014296124817752\n",
      "Layer 16: Accuracy=0.8338709677419355, F1=0.8312922007905631\n",
      "Layer 17: Accuracy=0.8451612903225807, F1=0.8427118392113014\n",
      "Layer 18: Accuracy=0.8596774193548387, F1=0.856900933222621\n",
      "Layer 19: Accuracy=0.8629032258064516, F1=0.8615426879290937\n",
      "Layer 20: Accuracy=0.8596774193548387, F1=0.8585957568723808\n",
      "Layer 21: Accuracy=0.853225806451613, F1=0.8526541183911976\n",
      "Layer 22: Accuracy=0.8596774193548387, F1=0.8598278174087878\n",
      "Layer 23: Accuracy=0.8596774193548387, F1=0.8583879807282557\n",
      "Layer 24: Accuracy=0.8580645161290322, F1=0.8572900326912793\n",
      "Layer 25: Accuracy=0.8661290322580645, F1=0.8647897154656835\n",
      "Layer 26: Accuracy=0.8661290322580645, F1=0.8653909641707485\n",
      "Layer 27: Accuracy=0.8612903225806452, F1=0.8608397716090772\n",
      "Layer 28: Accuracy=0.8629032258064516, F1=0.8616696037339869\n",
      "Layer 29: Accuracy=0.8596774193548387, F1=0.8576952725266379\n",
      "Layer 30: Accuracy=0.8564516129032258, F1=0.8551063577225246\n",
      "Layer 31: Accuracy=0.8548387096774194, F1=0.853711429746903\n",
      "Layer 32: Accuracy=0.864516129032258, F1=0.8622590919852937\n"
     ]
    }
   ],
   "source": [
    "# Train classifiers for each layer\n",
    "trained_classifiers = {}\n",
    "\n",
    "for i, layer_data in enumerate(layer_representations):\n",
    "    X = np.array([x[0] for x in layer_data])\n",
    "    y = np.array([x[1] for x in layer_data])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Convert data to tensors\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "\n",
    "    # Initialize a new classifier for this layer\n",
    "    layer_classifier = SharedNN(input_size=model.config.hidden_size, num_classes=len(set(train_data['gold']))).to(device)\n",
    "    optimizer = optim.Adam(layer_classifier.parameters(), lr=2e-4)\n",
    "\n",
    "    # Train the classifier\n",
    "    layer_classifier.train()\n",
    "    for epoch in range(200):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = layer_classifier(X_train_tensor)\n",
    "        loss = criterion(outputs, y_train_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluate the classifier\n",
    "    layer_classifier.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = torch.argmax(layer_classifier(X_test_tensor), dim=1).cpu().numpy()\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "\n",
    "    print(f\"Layer {i}: Accuracy={accuracy}, F1={f1}\")\n",
    "    layer_metrics.append((i, accuracy, f1))\n",
    "\n",
    "    # Store the trained classifier\n",
    "    trained_classifiers[i] = layer_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "393300d3-2b54-42e5-befb-61b3e75963a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Best Layers (Dynamic Margin Based on Std Dev): [15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the standard deviation for accuracy and F1\n",
    "accuracy_std = np.std([accuracy for _, accuracy, _ in layer_metrics])\n",
    "f1_std = np.std([f1 for _, _, f1 in layer_metrics])\n",
    "margin_accuracy = 0.5 * accuracy_std\n",
    "margin_f1 = 0.5 * f1_std\n",
    "\n",
    "best_layers = []\n",
    "\n",
    "# Find layers that are not strictly dominated\n",
    "for i, accuracy, f1 in layer_metrics:\n",
    "    is_dominated = False\n",
    "    for j, acc, f in layer_metrics:\n",
    "        if (acc >= accuracy + margin_accuracy) and (f >= f1 + margin_f1) and j != i:\n",
    "            is_dominated = True\n",
    "            break\n",
    "    if not is_dominated and i not in best_layers:  # Check if already in list\n",
    "        best_layers.append(i)\n",
    "\n",
    "print(f\"Selected Best Layers (Dynamic Margin Based on Std Dev): {best_layers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3b7c4bb-b109-4382-a85a-c7bc5c5be10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all layers except best layers\n",
    "def freeze_non_best_layers(model, best_layers):\n",
    "    for idx, layer in enumerate(model.model.layers):\n",
    "        requires_grad = idx in best_layers\n",
    "        for param in layer.parameters():\n",
    "            param.requires_grad = requires_grad\n",
    "\n",
    "freeze_non_best_layers(model, best_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87ad0f55-2cd4-4400-8292-e321bd7f5f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters in model: 2122294272\n",
      "Total trainable parameters in classifier: 401795\n",
      "Total trainable parameters (model + classifier): 2122696067\n"
     ]
    }
   ],
   "source": [
    "def count_trainable_parameters(model, ensemble_clf):\n",
    "    model_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    clf_params = sum(p.numel() for p in shared_nn.parameters() if p.requires_grad)\n",
    "    \n",
    "    total_params = model_params + clf_params\n",
    "    \n",
    "    return model_params, clf_params, total_params\n",
    "\n",
    "# Assuming you've frozen some layers in the model and ensemble_clf is your classifier\n",
    "model_params, clf_params, total_params = count_trainable_parameters(model, shared_nn)\n",
    "\n",
    "print(f\"Total trainable parameters in model: {model_params}\")\n",
    "print(f\"Total trainable parameters in classifier: {clf_params}\")\n",
    "print(f\"Total trainable parameters (model + classifier): {total_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea94dae4-dfea-469e-8f15-bd9f12d6c3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_with_voting(valid_data, best_layers, trained_classifiers):\n",
    "    \"\"\"\n",
    "    Evaluate using a voting ensemble of classifiers for the best-performing layers.\n",
    "    \n",
    "    Args:\n",
    "        valid_data: Validation dataset.\n",
    "        best_layers: List of indices of the best-performing layers.\n",
    "        trained_classifiers: Dictionary of trained classifiers for each layer.\n",
    "    \"\"\"\n",
    "    model.eval()  # Ensure the LLM is in evaluation mode\n",
    "    shared_nn.eval()  # Ensure the classifier is in evaluation mode\n",
    "    \n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    total_inference_time = 0  # To accumulate inference time\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for example in tqdm(valid_data):\n",
    "            input_text, label = preprocess(example)\n",
    "            label = torch.tensor([label]).to(device)\n",
    "\n",
    "            # Tokenize input\n",
    "            inputs = tokenizer(\n",
    "                input_text,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=400\n",
    "            ).to(device)\n",
    "\n",
    "            # Record the start time for inference\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Forward pass through the LLM (model)\n",
    "            outputs = model(**inputs, output_hidden_states=True)\n",
    "\n",
    "            # Calculate inference time for the LLM forward pass\n",
    "            inference_time = time.time() - start_time\n",
    "            total_inference_time += inference_time  # Accumulate inference time\n",
    "\n",
    "            # Collect predictions from classifiers (shared_nn)\n",
    "            predictions = []\n",
    "            for layer_idx in best_layers:\n",
    "                layer_output = outputs.hidden_states[layer_idx][0, -1, :].float()\n",
    "                logits = shared_nn(layer_output)  # Using shared_nn as classifier\n",
    "                pred = torch.argmax(logits, dim=0).cpu().item()\n",
    "                predictions.append(pred)\n",
    "\n",
    "            # Voting ensemble\n",
    "            final_prediction = max(set(predictions), key=predictions.count)\n",
    "\n",
    "            total_correct += (final_prediction == label.cpu().item())\n",
    "            total_samples += 1\n",
    "\n",
    "            y_true.append(label.cpu().item())\n",
    "            y_pred.append(final_prediction)\n",
    "\n",
    "            # Print inference time for this sample (optional)\n",
    "            #print(f\"Inference Time for Sample {total_samples}: {inference_time:.4f} seconds\")\n",
    "\n",
    "    # Metrics\n",
    "    accuracy = total_correct / total_samples\n",
    "    f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "    avg_inference_time = total_inference_time / total_samples  # Average inference time per sample\n",
    "    print(f\"Evaluation Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}\")\n",
    "    print(f\"Average Inference Time per Sample: {avg_inference_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fff73f-7eac-4d4a-a4cf-0c37111f5ac2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "from torch.optim import Adam\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "def fine_tune_with_ensemble(train_data, valid_data, best_layers, trained_classifiers):\n",
    "    \"\"\"\n",
    "    Fine-tune the best layers of the LLM and their associated classifiers.\n",
    "    \n",
    "    Args:\n",
    "        train_data: Training dataset.\n",
    "        valid_data: Validation dataset.\n",
    "        best_layers: List of indices of the best-performing layers.\n",
    "        trained_classifiers: Dictionary of trained classifiers for each layer.\n",
    "    \"\"\"\n",
    "    model.train()  # Set LLM to training mode\n",
    "    shared_nn.train()  # Set classifier to training mode\n",
    "    \n",
    "    # Prepare optimizer for fine-tuning both the layers (LLM) and their classifiers (shared_nn)\n",
    "    optimizer = Adam([\n",
    "        {\"params\": model.parameters(), \"lr\": 5e-5, \"weight_decay\": 1e-4},  # LLM parameters\n",
    "        {\"params\": [param for i in best_layers for param in trained_classifiers[i].parameters()], \"lr\": 1e-4}  # Classifier parameters\n",
    "    ])\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    total_train_loss = 0  # Variable to accumulate training loss\n",
    "\n",
    "    for epoch in range(100):\n",
    "        total_train_loss = 0\n",
    "        epoch_start_time = time.time()\n",
    "    \n",
    "        for example in tqdm(train_data):\n",
    "            input_text, label = preprocess(example)\n",
    "            label = torch.tensor([label]).to(device)\n",
    "    \n",
    "            # Tokenize input\n",
    "            inputs = tokenizer(\n",
    "                input_text,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=400\n",
    "            ).to(device)\n",
    "    \n",
    "            # Forward pass\n",
    "            outputs = model(**inputs, output_hidden_states=True)\n",
    "    \n",
    "            # Loss for each layer\n",
    "            layer_losses = []\n",
    "            for layer_idx in best_layers:\n",
    "                layer_output = outputs.hidden_states[layer_idx][0, -1, :].float()\n",
    "                logits = shared_nn(layer_output)\n",
    "                loss = criterion(logits.unsqueeze(0), label)\n",
    "                layer_losses.append(loss)\n",
    "    \n",
    "            # Average or sum layer losses\n",
    "            total_layer_loss = sum(layer_losses)  # Average loss\n",
    "            optimizer.zero_grad()\n",
    "            total_layer_loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            total_train_loss += total_layer_loss.item()\n",
    "    \n",
    "\n",
    "        # Calculate and print time taken for each epoch\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        print(f\"Epoch {epoch + 1}, Total Loss: {total_train_loss:.4f}, Time Taken: {epoch_time:.4f}s\")\n",
    "\n",
    "        # Evaluate after each epoch\n",
    "        print(f\"Evaluating at Epoch {epoch + 1}...\")\n",
    "        evaluate_with_voting(valid_data, best_layers, trained_classifiers)\n",
    "        evaluate_with_voting(test_data, best_layers, trained_classifiers)\n",
    "\n",
    "fine_tune_with_ensemble(train_data, valid_data, best_layers, trained_classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e34cfb8-2fea-4acc-8972-fd194b3d6ee8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f188c700-0931-445d-b113-1a1f048b751c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
